{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5e65e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "import urllib\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import glob \n",
    "\n",
    "currentDir = os.getcwd()\n",
    "zipURLList = []\n",
    "data_frames = []\n",
    "oldCount = 0\n",
    "newCount = 0\n",
    "\n",
    "url = 'http://data.gdeltproject.org/gdeltv2/lastupdate.txt'\n",
    "regex = '(?:(?:https?|ftp):\\/\\/)?[\\w/\\-?=%.]+\\.[\\w/\\-&?=%.]+'\n",
    "\n",
    "def remove_duplicates_list(urlList):\n",
    "    urlList = list(dict.fromkeys(urlList))\n",
    "    return urlList\n",
    "\n",
    "pattern = currentDir + \"/*.csv\"\n",
    "csvFileName = currentDir + \"\\\\one_giant_file.csv\"\n",
    "f = open(csvFileName,'w')\n",
    "\n",
    "starttime = time.time()\n",
    "\n",
    "while True:\n",
    "    urllib.request.urlretrieve(url,'dataLink.txt')\n",
    "    \n",
    "    oldCount = len(zipURLList)\n",
    "    print(zipURLList)\n",
    "    \n",
    "    with open(\"dataLink.txt\") as file:\n",
    "        zipURLList.append(re.findall(regex, file.readline())[0])\n",
    "    zipURLList = remove_duplicates_list(zipURLList)\n",
    "    newCount = len(zipURLList)\n",
    "\n",
    "    if oldCount > 0 and newCount > oldCount :\n",
    "        print(\"isUpdated\")\n",
    "        with urlopen(zipURLList[0]) as zipresp:\n",
    "            with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "                zfile.extractall(currentDir)   \n",
    "                      \n",
    "        csvFile = glob.glob(pattern)\n",
    "        existingDf = pd.read_csv(csvFileName)\n",
    "        print(existingDf.shape)\n",
    "        print(\"existing\")\n",
    "        data_frames.append(existingDf)\n",
    "        del existingDf\n",
    "        newDf = pd.read_csv(csvFile[0], sep='\\t', engine='python',keep_default_na=True)\n",
    "        print(newDf.shape)\n",
    "        print(\"new\")\n",
    "        data_frames.append(newDf)\n",
    "        del newDf\n",
    "    else:\n",
    "        with urlopen(zipURLList[0]) as zipresp:\n",
    "            with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "                zfile.extractall(currentDir) \n",
    "            \n",
    "        csvFile = glob.glob(pattern)\n",
    "        df = pd.read_csv(csvFile[0], sep='\\t', engine='python',keep_default_na=True)\n",
    "        \n",
    "    data_frames.append(df)\n",
    "    del df\n",
    "    os.remove(csvFile[0])\n",
    "    \n",
    "    big_un = pd.concat(data_frames, ignore_index=True,sort=False)\n",
    "    big_un.drop_duplicates(inplace=True)\n",
    "    big_un.to_csv(csvFileName)\n",
    "        \n",
    "    df = pd.read_csv(csvFileName)\n",
    "    print(\"Final Frame\")\n",
    "    print(df.shape)\n",
    "    df.to_parquet('output.parquet')\n",
    "    parFile = pd.read_parquet('example_pa.parquet', engine='pyarrow')\n",
    "    print(parFile)\n",
    "    time.sleep((15*60) - ((time.time() - starttime) % (15*60)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
